import requests
from bs4 import BeautifulSoup
import os
from googletrans import Translator
from datetime import datetime, timezone
from email.utils import parsedate_to_datetime

DISCORD_WEBHOOK_URL = os.environ['DISCORD_WEBHOOK']
KEYWORDS = ['ë¶‰ì€ì‚¬ë§‰', 'Crimson Desert', 'í„ì–´ë¹„ìŠ¤', 'Pearl Abyss']
LANG_SETTINGS = [
    ("ko", "KR", "KR:ko"),  # í•œêµ­ì–´ ë‰´ìŠ¤
    ("en", "US", "US:en")   # ê¸€ë¡œë²Œ ì˜ì–´ ë‰´ìŠ¤
]

translator = Translator()
sent_links = set()

def fetch_news(keyword, lang, gl, ceid):
    url = f"https://news.google.com/rss/search?q={keyword}&hl={lang}&gl={gl}&ceid={ceid}"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'lxml-xml')
    return soup.find_all('item')[:5]

def check_news():
    today = datetime.now(timezone.utc).date()  # ì˜¤ëŠ˜ ë‚ ì§œ (UTC ê¸°ì¤€)
    for keyword in KEYWORDS:
        for lang, gl, ceid in LANG_SETTINGS:
            items = fetch_news(keyword, lang, gl, ceid)
            for item in items:
                title = item.title.text
                link = item.link.text
                pub_date = parsedate_to_datetime(item.pubDate.text)
                description = item.description.text if item.description else ""

                # ì˜¤ëŠ˜ ê¸°ì‚¬ë§Œ í•„í„°ë§
                if pub_date.date() != today:
                    continue

                if link in sent_links:
                    continue
                sent_links.add(link)

                # ë²ˆì—­ (ì˜ë¬¸ì¼ ê²½ìš°ë§Œ)
                if lang == "en":
                    title = translator.translate(title, src="en", dest="ko").text
                    description = translator.translate(description, src="en", dest="ko").text

                # ìš”ì•½ ë©”ì‹œì§€
                message = f"ğŸ“¢ **[{keyword}] ìƒˆ ì†Œì‹**\nì œëª©: {title}\nìš”ì•½: {description[:150]}...\në§í¬: {link}"
                requests.post(DISCORD_WEBHOOK_URL, json={"content": message})
                break  # ìµœì‹  ê¸°ì‚¬ í•˜ë‚˜ë§Œ ë³´ë‚´ê¸°

if __name__ == "__main__":
    check_news()
